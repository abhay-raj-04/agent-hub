# Resume AI Co-Pilot - Organized Structure

A comprehensive AI-powered resume analysis and interview preparation tool built with LangGraph and Streamlit.

## ğŸ—ï¸ Project Structure

```
agent-hub/
â”œâ”€â”€ src/                          # Main source code
â”‚   â”œâ”€â”€ core/                     # Core agent logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_ingestion.py # Document processing
â”‚   â”‚   â”œâ”€â”€ router.py             # Intent classification
â”‚   â”‚   â”œâ”€â”€ analyzer.py           # Resume analysis
â”‚   â”‚   â”œâ”€â”€ quiz_generator.py     # Interview questions
â”‚   â”‚   â”œâ”€â”€ rewriter.py           # Resume improvements
â”‚   â”‚   â””â”€â”€ formatter.py          # Response formatting
â”‚   â”œâ”€â”€ prompts/                  # All prompt templates
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ router_prompts.py     # Routing prompts
â”‚   â”‚   â”œâ”€â”€ analysis_prompts.py   # Analysis prompts
â”‚   â”‚   â”œâ”€â”€ quiz_prompts.py       # Quiz generation prompts
â”‚   â”‚   â”œâ”€â”€ rewrite_prompts.py    # Rewrite prompts
â”‚   â”‚   â”œâ”€â”€ fallback_prompts.py   # Fallback responses
â”‚   â”‚   â””â”€â”€ system_prompts.py     # System messages
â”‚   â”œâ”€â”€ ui/                       # User interface
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ streamlit_app.py      # Main UI
â”‚   â”‚   â””â”€â”€ streamlit_app_streaming.py # Streaming UI
â”‚   â”œâ”€â”€ workflow/                 # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ langgraph_setup.py   # Workflow configuration
â”‚   â”œâ”€â”€ config/                   # Configuration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ llm_config.py        # LLM configuration
â”‚   â”œâ”€â”€ types/                    # Type definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ state.py             # State management
â”‚   â”œâ”€â”€ utils/                    # Utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ debug_router.py      # Router debugging
â”‚   â”‚   â””â”€â”€ test_gemini.py       # LLM testing
â”‚   â””â”€â”€ __init__.py              # Main package init
â”œâ”€â”€ main.py                      # Main entry point
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ README.md                    # Original README
â””â”€â”€ README_ORGANIZED.md          # This file
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Set Environment Variables
Create a `.env` file in the root directory:
```bash
GOOGLE_API_KEY=your_google_api_key_here
```

### 3. Test LLM Integration
```bash
python main.py --test-gemini
```

### 4. Run the Application
```bash
streamlit run main.py
```

## ğŸ“ Module Breakdown

### Core Module (`src/core/`)
- **document_ingestion.py**: Handles PDF/DOCX file parsing
- **router.py**: Classifies user intent using LLM
- **analyzer.py**: Performs resume analysis with streaming support
- **quiz_generator.py**: Generates interview questions
- **rewriter.py**: Improves resume sections
- **formatter.py**: Formats responses for UI

### Prompts Module (`src/prompts/`)
- **router_prompts.py**: Intent classification prompts
- **analysis_prompts.py**: Resume analysis prompts
- **quiz_prompts.py**: Interview question generation
- **rewrite_prompts.py**: Resume improvement prompts
- **fallback_prompts.py**: Error fallback responses
- **system_prompts.py**: System messages and greetings

### UI Module (`src/ui/`)
- **streamlit_app.py**: Main Streamlit interface
- **streamlit_app_streaming.py**: Real-time streaming interface

### Workflow Module (`src/workflow/`)
- **langgraph_setup.py**: LangGraph workflow configuration

### Config Module (`src/config/`)
- **llm_config.py**: LLM initialization and configuration

### Types Module (`src/types/`)
- **state.py**: TypedDict for state management

### Utils Module (`src/utils/`)
- **debug_router.py**: Router debugging utilities
- **test_gemini.py**: LLM testing utilities

## ğŸ”§ Key Features

### 1. Modular Architecture
- **Separation of Concerns**: Each module has a specific responsibility
- **Easy Maintenance**: Small, focused files (150-200 lines max)
- **Clear Dependencies**: Explicit imports and dependencies

### 2. Dual LLM Strategy
- **Gemini Flash**: Fast routing and simple tasks
- **Gemini Pro**: High-quality analysis and complex tasks
- **Think Mode Toggle**: User can choose between speed and quality

### 3. Streaming Support
- **Real-time Responses**: Character-by-character streaming
- **Progress Indicators**: Visual feedback during processing
- **Fallback Handling**: Graceful error recovery

### 4. Document Processing
- **Multi-format Support**: PDF, DOCX, TXT files
- **Auto-processing**: Automatic text extraction
- **Error Handling**: Robust file processing

## ğŸ¯ Usage Examples

### Resume Analysis
```
User: "Analyze my resume for this software engineering role"
â†’ Router: ANALYZE
â†’ Analyzer: Comprehensive resume vs JD analysis
```

### Interview Questions
```
User: "Generate interview questions based on my experience"
â†’ Router: QUIZ
â†’ Quiz Generator: Personalized behavioral questions
```

### Resume Improvements
```
User: "Rewrite this bullet point: 'Managed projects'"
â†’ Router: REWRITE
â†’ Rewriter: Improved version with metrics
```

## ğŸ› ï¸ Development

### Adding New Features
1. **Core Logic**: Add to appropriate module in `src/core/`
2. **Prompts**: Create new prompt file in `src/prompts/`
3. **UI**: Update relevant file in `src/ui/`
4. **Workflow**: Modify `src/workflow/langgraph_setup.py`

### Testing
```bash
# Test LLM integration
python main.py --test-gemini

# Debug router logic
python main.py --debug-router

# Run streaming version
streamlit run src/ui/streamlit_app_streaming.py
```

### Code Organization Principles
- **Single Responsibility**: Each file has one clear purpose
- **Dependency Injection**: Clear import structure
- **Error Handling**: Comprehensive fallback mechanisms
- **Type Safety**: TypedDict for state management
- **Documentation**: Clear docstrings and comments

## ğŸ“Š File Size Analysis

| Module | Files | Avg Lines | Purpose |
|--------|-------|-----------|---------|
| Core | 6 | ~80 | Agent logic |
| Prompts | 6 | ~40 | LLM prompts |
| UI | 2 | ~150 | User interface |
| Workflow | 1 | ~50 | LangGraph setup |
| Config | 1 | ~30 | LLM config |
| Types | 1 | ~15 | Type definitions |
| Utils | 2 | ~70 | Debug/testing |

**Total**: 19 files, average ~60 lines per file

## ğŸ”„ Migration from Old Structure

The old monolithic files have been broken down:

- `agent_core.py` (407 lines) â†’ 6 core modules (~80 lines each)
- `prompts.py` (247 lines) â†’ 6 prompt modules (~40 lines each)
- `streamlit_app.py` (194 lines) â†’ UI modules (~150 lines each)

## ğŸ‰ Benefits of New Structure

1. **Maintainability**: Easy to find and modify specific functionality
2. **Testability**: Individual modules can be tested in isolation
3. **Scalability**: New features can be added without affecting existing code
4. **Readability**: Smaller files are easier to understand
5. **Collaboration**: Multiple developers can work on different modules
6. **Documentation**: Clear module boundaries and responsibilities

## ğŸš€ Next Steps

1. **Add Unit Tests**: Create tests for each module
2. **Add Logging**: Implement comprehensive logging
3. **Add Configuration**: Environment-based configuration
4. **Add Monitoring**: Performance and usage metrics
5. **Add CI/CD**: Automated testing and deployment

---

**Note**: This organized structure maintains all original functionality while making the codebase much more maintainable and scalable. 